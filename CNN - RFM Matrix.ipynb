{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib._util.visualplot as vp\n",
    "import lib._util.fileproc as fp\n",
    "\n",
    "from lib._class.DataGenerator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "# Time measurement\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Sound notification\n",
    "import winsound\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_CODE      = 'MAG'\n",
    "TARGET            = 'target4'\n",
    "SOURCE_PATH_RFM   = f'resources/output/eda_rfm/file/{COMPANY_CODE}/Moving RFM/'\n",
    "SOURCE_PATH_TRANS = f'resources/output/eda_trans/file/{COMPANY_CODE}/'\n",
    "OUT_PATH_GRAPH    = f'resources/output/cnn_rfm/graph/{COMPANY_CODE}/'\n",
    "OUT_PATH_FILE     = f'resources/output/cnn_rfm/file/{COMPANY_CODE}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken(seconds):\n",
    "    print(f'\\nTime Taken: {str(timedelta(seconds=seconds))}')\n",
    "    winsound.Beep(frequency=1000, duration=100)\n",
    "    winsound.Beep(frequency=1500, duration=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Feature Loading\n",
    "- Load periods having all numbers occured at least once\n",
    "- Convert features to transaction format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moving_rfm(company_code, start_year=None, end_year=None):\n",
    "    files      = glob.glob(f'{SOURCE_PATH_RFM}{company_code} - *.csv')\n",
    "    files_dict = {x: int(x[x.index('.csv') - 4: x.index('.csv')]) for x in files}\n",
    "    files      = [k for k,v in files_dict.items()\n",
    "                  if (True if start_year is None else v >= start_year) and (True if end_year is None else v <= end_year)]\n",
    "    \n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        df_chunks = pd.read_csv(file, sep=';', dtype={'number': str},\n",
    "                                parse_dates=['date'],\n",
    "                                date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'),\n",
    "                                chunksize=50_000)\n",
    "        df = pd.concat(df_chunks)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "date       = '2013-11-17' if COMPANY_CODE == 'MAG' else '2016-11-27' if COMPANY_CODE == 'DMC' else '2015-05-27' if COMPANY_CODE == 'ST' else None\n",
    "start_year = 2013 if COMPANY_CODE == 'MAG' else 2016 if COMPANY_CODE == 'DMC' else 2015 if COMPANY_CODE == 'ST' else None\n",
    "end_year   = 2020\n",
    "\n",
    "feature_df = load_moving_rfm(COMPANY_CODE, start_year=start_year, end_year=end_year)\n",
    "feature_df = feature_df[feature_df['date'] >= date].reset_index(drop=True).copy()\n",
    "\n",
    "vp.faststat(feature_df)\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to transaction format\n",
    "recency_df = pd.DataFrame(feature_df['recency'].values.reshape(-1, 10000))\n",
    "recency_df.rename(columns={x: f'recency_{str(x).zfill(4)}' for x in recency_df.columns}, inplace=True)\n",
    "\n",
    "frequency_df = pd.DataFrame(feature_df['frequency'].values.reshape(-1, 10000))\n",
    "frequency_df.rename(columns={x: f'frequency_{str(x).zfill(4)}' for x in frequency_df.columns}, inplace=True)\n",
    "\n",
    "monetary_df = pd.DataFrame(feature_df['monetary'].values.reshape(-1, 10000))\n",
    "monetary_df.rename(columns={x: f'monetary_{str(x).zfill(4)}' for x in monetary_df.columns}, inplace=True)\n",
    "\n",
    "date_df = pd.DataFrame(feature_df['date'].unique(), columns=['draw_date'])\n",
    "\n",
    "del feature_df\n",
    "\n",
    "recency_df.shape, frequency_df.shape, monetary_df.shape, date_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile transaction features\n",
    "feature_df = date_df.merge(recency_df, left_index=True, right_index=True, how='left')\n",
    "feature_df = feature_df.merge(frequency_df, left_index=True, right_index=True, how='left')\n",
    "feature_df = feature_df.merge(monetary_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "del recency_df, frequency_df, monetary_df, date_df\n",
    "\n",
    "vp.faststat(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Target Loading\n",
    "- Create target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target(filename):\n",
    "    source_file = f'{SOURCE_PATH_TRANS}{filename}'\n",
    "    df_chunks   = pd.read_csv(source_file, sep=';',\n",
    "                              usecols=['draw_date', 'draw_period', '1st'],\n",
    "                              dtype={'1st': str},\n",
    "                              parse_dates=['draw_date'],\n",
    "                              date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'),\n",
    "                              chunksize=50_000)\n",
    "    return pd.concat(df_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = load_target(f'{COMPANY_CODE} - transactions.csv')\n",
    "\n",
    "vp.faststat(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take target from following period\n",
    "target_df['target'] = target_df['1st'].shift(-1)\n",
    "\n",
    "# Split target into digits\n",
    "for index in [x for x in range(4)]:\n",
    "    column = f'target{4 - index}'\n",
    "    target_df[column] = target_df['target'].apply(lambda x: x[index] if x == x else x)\n",
    "    target_df[column] = target_df[column].astype(float).astype('Int8')\n",
    "\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.drop(columns=['1st', 'target'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Dataset\n",
    "- Map target label to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.shape, target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = feature_df.merge(target_df, on='draw_date', how='inner')\n",
    "\n",
    "del feature_df, target_df\n",
    "\n",
    "vp.faststat(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)\n",
    "\n",
    "columns = [x for x in data_df.columns if any([x.startswith(y) for y in ['1st', 'target']])]\n",
    "data_df[columns] = data_df[columns].astype(int)\n",
    "\n",
    "# Target distribution\n",
    "print('Full dataset:')\n",
    "vp.value_count(data_df, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_target(df, target, n_remain, excludes=[], random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    dfs = []\n",
    "    for target_label in np.unique(df[target]):\n",
    "        indexes = df[df[target] == target_label].index\n",
    "        indexes = [x for x in indexes if x not in excludes]\n",
    "        \n",
    "        choices = np.random.choice(indexes, size=n_remain, replace=False)\n",
    "        dfs.append(df[df.index.isin(choices)].copy())\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train & validation dataset with balanced target label\n",
    "train_df = balanced_target(data_df, target=TARGET, n_remain=55, random_state=10000)\n",
    "valid_df = balanced_target(data_df, target=TARGET, n_remain=25, random_state=10000, excludes=train_df.index)\n",
    "\n",
    "# Remaining goes to test dataset\n",
    "used_indexes = list(train_df.index) + list(valid_df.index)\n",
    "test_df      = data_df[~data_df.index.isin(used_indexes)].copy()\n",
    "\n",
    "# Shuffle dataset\n",
    "train_df = train_df.sample(frac=1, random_state=0)\n",
    "valid_df = valid_df.sample(frac=1, random_state=0)\n",
    "test_df  = test_df.sample(frac=1, random_state=0)\n",
    "\n",
    "del data_df\n",
    "\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset:')\n",
    "vp.value_count(train_df, TARGET)\n",
    "\n",
    "print('\\nValidate dataset:')\n",
    "vp.value_count(valid_df, TARGET)\n",
    "\n",
    "print('\\nTest dataset:')\n",
    "vp.value_count(test_df, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_period(df, title):\n",
    "    sample_df = df.copy()\n",
    "    sample_df['year_month'] = sample_df['draw_date'].dt.to_period('M').astype(str)\n",
    "    sample_df = sample_df.groupby(['dataset', 'year_month']).agg(\n",
    "        count=('year_month', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    fig = px.bar(sample_df, x='year_month', y='count', facet_row='dataset')\n",
    "    vp.generate_plot(fig,\n",
    "                     out_path=OUT_PATH_GRAPH,\n",
    "                     out_filename=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dataset'] = 'train'\n",
    "valid_df['dataset'] = 'validate'\n",
    "test_df['dataset']  = 'test'\n",
    "\n",
    "sampling_period(pd.concat([train_df, valid_df, test_df]),\n",
    "                title='Phase 3 - Bar - Draw Date (Sample)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 - Classification\n",
    "- Separate dataset to features & target\n",
    "- Feature scaling\n",
    "- Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X):\n",
    "    new_X = []\n",
    "    \n",
    "    # NOTE: Normalize each matrix to range from 0 - 1 individually\n",
    "    for x in X:\n",
    "        _min  = np.amin(x)\n",
    "        _max  = np.amax(x)\n",
    "        new_x = (x - _min) / (_max - _min)\n",
    "        new_X.append(new_x)\n",
    "        \n",
    "    return np.array(new_X)\n",
    "\n",
    "def feature_target_split(df):\n",
    "    recency_X   = df[[x for x in df.columns if x.startswith('recency_')]].values.reshape(-1, 100, 100)\n",
    "    frequency_X = df[[x for x in df.columns if x.startswith('frequency_')]].values.reshape(-1, 100, 100)\n",
    "    monetary_X  = df[[x for x in df.columns if x.startswith('monetary_')]].values.reshape(-1, 100, 100)\n",
    "    \n",
    "    # Feature scaling\n",
    "    recency_X   = feature_scaling(recency_X)\n",
    "    frequency_X = feature_scaling(frequency_X)\n",
    "    monetary_X  = feature_scaling(monetary_X)\n",
    "    \n",
    "    X = np.stack([recency_X, frequency_X, monetary_X], axis=3)\n",
    "    y = df[TARGET]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features & target\n",
    "X_train, y_train = feature_target_split(train_df)\n",
    "X_valid, y_valid = feature_target_split(valid_df)\n",
    "X_test,  y_test  = feature_target_split(test_df)\n",
    "\n",
    "del train_df, valid_df, test_df\n",
    "\n",
    "print('Train dataset:')\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print('\\nValidate dataset:')\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "print('\\nTest dataset:')\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_reshape(y):\n",
    "    return to_categorical(y, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target reshaping\n",
    "y_train = target_reshape(y_train)\n",
    "y_valid = target_reshape(y_valid)\n",
    "y_test  = target_reshape(y_test)\n",
    "\n",
    "print('Train target:')\n",
    "print(y_train.shape)\n",
    "\n",
    "print('\\nValidate target:')\n",
    "print(y_valid.shape)\n",
    "\n",
    "print('\\nTest target:')\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(X):\n",
    "    input_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1),\n",
    "                     padding='same', activation='relu', kernel_initializer='he_uniform',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1),\n",
    "                     padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1),\n",
    "                     padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1),\n",
    "                     padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(rate=.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Referecence: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "    metrics = [\n",
    "        'acc',\n",
    "        AUC(name='auc'),\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "    ]\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=.001, epsilon=.00001),\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
    "lrate = ReduceLROnPlateau(monitor='val_auc', factor=0.95, patience=15)\n",
    "\n",
    "# Reference: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=30, restore_best_weights=True)\n",
    "\n",
    "model   = compile_model(X_train)\n",
    "history = model.fit_generator(\n",
    "    DataGenerator(X_train, y_train, batch_size=1),\n",
    "    validation_data=DataGenerator(X_valid, y_valid, batch_size=1),\n",
    "    epochs=100,\n",
    "    callbacks=[lrate, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classif(X, y, model):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    \n",
    "    cofmat_df = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "    cofmat_df.index.name   = 'True'\n",
    "    cofmat_df.columns.name = 'Pred'\n",
    "\n",
    "    print(cofmat_df)\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation\n",
    "eval_classif(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set evaluation\n",
    "eval_classif(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set evaluation\n",
    "eval_classif(X_valid, y_valid, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "data = []\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['lr'],\n",
    "    mode='lines',\n",
    "    name='LR',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[-1]},\n",
    "))\n",
    "fig1 = go.Figure(data=data)\n",
    "\n",
    "# Loss\n",
    "data = []\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['loss'],\n",
    "    mode='lines',\n",
    "    name='loss',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[0]},\n",
    "    legendgroup='train',\n",
    "))\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['val_loss'],\n",
    "    mode='lines',\n",
    "    name='val_loss',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[1]},\n",
    "    legendgroup='validate',\n",
    "))\n",
    "fig2 = go.Figure(data=data)\n",
    "\n",
    "# Accuracy\n",
    "data = []\n",
    "data.append(go.Scattergl(\n",
    "    y=history.history['acc'],\n",
    "    mode='lines',\n",
    "    name='accuracy',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[0]},\n",
    "    legendgroup='train',\n",
    "))\n",
    "data.append(go.Scattergl(\n",
    "    y=history.history['val_acc'],\n",
    "    mode='lines',\n",
    "    name='val_accuracy',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[1]},\n",
    "    legendgroup='validate',\n",
    "))\n",
    "fig3 = go.Figure(data=data)\n",
    "\n",
    "# AUC\n",
    "data = []\n",
    "data.append(go.Scattergl(\n",
    "    y=history.history['auc'],\n",
    "    mode='lines',\n",
    "    name='auc',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[0]},\n",
    "    legendgroup='train',\n",
    "))\n",
    "data.append(go.Scattergl(\n",
    "    y=history.history['val_auc'],\n",
    "    mode='lines',\n",
    "    name='val_auc',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[1]},\n",
    "    legendgroup='validate',\n",
    "))\n",
    "fig4 = go.Figure(data=data)\n",
    "\n",
    "# Precision\n",
    "data = []\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['precision'],\n",
    "    mode='lines',\n",
    "    name='precision',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[0]},\n",
    "    legendgroup='train',\n",
    "))\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['val_precision'],\n",
    "    mode='lines',\n",
    "    name='val_precision',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[1]},\n",
    "    legendgroup='validate',\n",
    "))\n",
    "fig5 = go.Figure(data=data)\n",
    "\n",
    "# Recall\n",
    "data = []\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['recall'],\n",
    "    mode='lines',\n",
    "    name='recall',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[0]},\n",
    "    legendgroup='train',\n",
    "))\n",
    "data.append(go.Scatter(\n",
    "    y=history.history['val_recall'],\n",
    "    mode='lines',\n",
    "    name='val_recall',\n",
    "    marker={'color': DEFAULT_PLOTLY_COLORS[1]},\n",
    "    legendgroup='validate',\n",
    "))\n",
    "fig6 = go.Figure(data=data)\n",
    "\n",
    "data_groups = [fig1['data'], fig2['data'], fig3['data'], fig4['data'], fig5['data'], fig6['data']]\n",
    "vp.datagroups_subplots(data_groups,\n",
    "                       max_col=3,\n",
    "                       title='Phase 4 - Metrics',\n",
    "                       out_path=OUT_PATH_GRAPH,\n",
    "                       subplot_titles=['Learning Rate', 'Loss', 'Accuracy', 'AUC', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
