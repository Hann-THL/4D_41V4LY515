{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Bokeh\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import Legend, HoverTool\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.palettes import Set1, Category20\n",
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../resources/data/4D_result_2018-01-01_2018-12-31.csv'\n",
    "raw_df = pd.read_csv(filename, sep=';', dtype={'number': str},\n",
    "                      parse_dates=['draw_date'],\n",
    "                      date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "# raw_df.info()\n",
    "# raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_df = raw_df.set_index('draw_date')\n",
    "transform_df.loc[transform_df['company_code'] == 'DMC', 'company_code'] = 'Da Ma Cai'\n",
    "transform_df.loc[transform_df['company_code'] == 'MAG', 'company_code'] = 'Magnum'\n",
    "transform_df.loc[transform_df['company_code'] == 'ST', 'company_code'] = 'Sports Toto'\n",
    "\n",
    "transform_df.loc[transform_df['category'] == 'FST', 'category'] = '1st'\n",
    "transform_df.loc[transform_df['category'] == 'SCD', 'category'] = '2nd'\n",
    "transform_df.loc[transform_df['category'] == 'TRD', 'category'] = '3rd'\n",
    "transform_df.loc[transform_df['category'] == 'SP', 'category'] = 'Special'\n",
    "transform_df.loc[transform_df['category'] == 'CONS', 'category'] = 'Consolation'\n",
    "# transform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = transform_df[(transform_df['number'] != '----')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Manipulation\n",
    "### 4.1 Populate clustering categories for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../resources/data/number_category.csv'\n",
    "category_df = pd.read_csv(filename, sep=';', dtype={'number': str})\n",
    "# category_df.info()\n",
    "# category_df.head()\n",
    "\n",
    "# Build dictionaries\n",
    "pattern_dict = dict(zip(category_df['number'], category_df['pattern']))\n",
    "group_4_dict = dict(zip(category_df['number'], category_df['group_4']))\n",
    "group_3_dict = dict(zip(category_df['number'], category_df['group_3']))\n",
    "group_2_dict = dict(zip(category_df['number'], category_df['group_2']))\n",
    "group_1_dict = dict(zip(category_df['number'], category_df['group_1']))\n",
    "odd_even_dict = dict(zip(category_df['number'], category_df['odd_even']))\n",
    "big_small_dict = dict(zip(category_df['number'], category_df['big_small']))\n",
    "\n",
    "# Dictionaries lookup\n",
    "data_df['pattern'] = [pattern_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['group_4'] = [group_4_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['group_3'] = [group_3_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['group_2'] = [group_2_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['group_1'] = [group_1_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['odd_even'] = [odd_even_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "data_df['big_small'] = [big_small_dict[row['number']] for index, row in data_df.iterrows()]\n",
    "# data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Visualization\n",
    "### 5.1 Lottery Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in data_df['company_code'].unique():\n",
    "    colors = itertools.cycle(Set1[9])\n",
    "    fig = figure(title=f'{company.title()} - Lottery Rewards',\n",
    "                 x_axis_type='datetime',\n",
    "                 x_axis_label='Dates', y_axis_label='Number',\n",
    "                 width=950, height=500,\n",
    "                 toolbar_location='above')\n",
    "    \n",
    "    items = []\n",
    "    for category in data_df['category'].unique():\n",
    "        tmp_df = data_df[(data_df['category'] == category) & (data_df['company_code'] == company)]\n",
    "        \n",
    "        source = ColumnDataSource(data=dict(\n",
    "            dates=tmp_df.index,\n",
    "            number=tmp_df['number'],\n",
    "            category=tmp_df['category'],\n",
    "        ))\n",
    "        glyph = fig.circle('dates', 'number', color=next(colors), alpha=.5, source=source)\n",
    "        items.append((category, [glyph]))\n",
    "\n",
    "    fig.add_layout(Legend(items=items, location='bottom_left', orientation='horizontal', click_policy='hide'), 'below')\n",
    "    fig.add_tools(HoverTool(\n",
    "        tooltips = [\n",
    "            ('Date', '@dates{%F}'),\n",
    "            ('Number', '@number'),\n",
    "            ('Price', '@category'),\n",
    "        ],\n",
    "        formatters={\n",
    "            'dates': 'datetime',\n",
    "        },\n",
    "        mode='mouse'\n",
    "    ))\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ABCD Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populateLineChart(data_df, group_by, splits_list, split_by='default', color_palette=Set1[9], title=''):\n",
    "    for company in data_df['company_code'].unique():\n",
    "        tmp_df = data_df[(data_df['company_code'] == company)]\n",
    "\n",
    "        groups_results = []\n",
    "        tmp_dict = tmp_df.groupby([tmp_df.index, group_by]).size().to_dict()\n",
    "        tmp_list = [x for x in tmp_dict.items()]\n",
    "\n",
    "        groups = tmp_df[group_by].unique()\n",
    "        groups.sort()\n",
    "        for group in groups:\n",
    "            tmp_data = list(filter(lambda x: x[0][1] == group, tmp_list))\n",
    "            groups_results.append((group, [(x[0][0], x[1]) for x in tmp_data]))\n",
    "\n",
    "        tmp_list = [[y[0] for y in x[1]] for x in groups_results]\n",
    "        dates = list(set(sum(tmp_list, [])))\n",
    "        dates.sort()\n",
    "\n",
    "        splits_results = []\n",
    "        for splits in splits_list:\n",
    "            if split_by == 'none':\n",
    "                splits_results.append(list(filter(lambda x: True, groups_results)))\n",
    "            elif split_by == 'groups_index':\n",
    "                splits_results.append(list(filter(lambda x: groups_results.index(x) in splits, groups_results)))\n",
    "            else:\n",
    "                splits_results.append(list(filter(lambda x: x[0] in splits, groups_results)))\n",
    "\n",
    "        for results in splits_results:\n",
    "            tmp_list = sorted([x[0] for x in results])\n",
    "            subtitle = ''\n",
    "            for index, splits in enumerate(splits_list):\n",
    "                if ((tmp_list == sorted(splits)) | (all(x in splits for x in tmp_list))) :\n",
    "                    subtitle = index < len(splits_list) -1 and f'{splits[0]} Pattern' or 'Other Pattern'\n",
    "                    break\n",
    "\n",
    "            colors = itertools.cycle(color_palette)\n",
    "            fig = figure(title=f'{company.title()} - {title}{subtitle}',\n",
    "                         x_axis_type='datetime',\n",
    "                         x_axis_label='Dates', y_axis_label='Number',\n",
    "                         width=950, height=500,\n",
    "                         toolbar_location='above')\n",
    "\n",
    "            items = []\n",
    "            for index, x in enumerate(results):\n",
    "                occurrences = [0 for date in dates]\n",
    "                group_dates = [y[0] for y in x[1]]\n",
    "                \n",
    "                for y in x[1]:\n",
    "                    if y[1] == 0:\n",
    "                        continue\n",
    "                    date = y[0]\n",
    "                    occurrences[dates.index(date)] = y[1]\n",
    "\n",
    "                source = ColumnDataSource(data=dict(\n",
    "                    dates=dates,\n",
    "                    occurrences=occurrences,\n",
    "                ))\n",
    "                color = next(colors)\n",
    "                glyph1 = fig.circle('dates', 'occurrences', color=color, alpha=.5, source=source)\n",
    "                glyph2 = fig.line('dates', 'occurrences', color=color, alpha=.8, source=source)\n",
    "                items.append((x[0], [glyph1, glyph2]))\n",
    "\n",
    "            fig.add_layout(Legend(items=items, location='bottom_left', orientation='horizontal', click_policy='hide'), 'below')\n",
    "            fig.add_tools(HoverTool(\n",
    "                tooltips = [\n",
    "                    ('Date', '@dates{%F}'),\n",
    "                    ('Occurrence', '@occurrences'),\n",
    "                ],\n",
    "                formatters={\n",
    "                    'dates': 'datetime',\n",
    "                },\n",
    "                mode='vline'\n",
    "            ))\n",
    "            show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern_list = list(set([x for x in pattern_dict.values()]))\n",
    "\n",
    "AAAB_patterns = ['AAAB', 'AABA', 'ABAA']\n",
    "AABB_patterns = ['AABB', 'ABAB', 'ABBA']\n",
    "AABC_patterns = ['AABC', 'ABAC', 'ABCA']\n",
    "ABBC_patterns = ['ABBC', 'ABCB']\n",
    "ABCD_other_patterns = list(\n",
    "    filter(lambda x: x not in AAAB_patterns + AABB_patterns + AABC_patterns + ABBC_patterns, pattern_list)\n",
    ")\n",
    "\n",
    "splits_list = [AAAB_patterns, AABB_patterns, AABC_patterns, ABBC_patterns, ABCD_other_patterns]\n",
    "populateLineChart(data_df, group_by='pattern', splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 N*** Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# populateLineChart(data_df, group_by='group_4', splits_list=splits_list, title='N*** Pattern', split_by='groups_index')\n",
    "\n",
    "splits_list = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "populateLineChart(data_df, group_by='group_4', splits_list=splits_list, title='N*** Pattern',\n",
    "                  split_by='none', color_palette=Category20[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 \\*N** Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# populateLineChart(data_df, group_by='group_3', splits_list=splits_list, title='*N** Pattern', split_by='groups_index')\n",
    "\n",
    "splits_list = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "populateLineChart(data_df, group_by='group_3', splits_list=splits_list, title='*N** Pattern',\n",
    "                  split_by='none', color_palette=Category20[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 \\*\\*N* Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# populateLineChart(data_df, group_by='group_2', splits_list=splits_list, title='**N* Pattern', split_by='groups_index')\n",
    "\n",
    "splits_list = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "populateLineChart(data_df, group_by='group_2', splits_list=splits_list, title='**N* Pattern',\n",
    "                  split_by='none', color_palette=Category20[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 \\*\\*\\*N Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# populateLineChart(data_df, group_by='group_1', splits_list=splits_list, title='***N Pattern', split_by='groups_index')\n",
    "\n",
    "splits_list = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "populateLineChart(data_df, group_by='group_1', splits_list=splits_list, title='***N Pattern',\n",
    "                  split_by='none', color_palette=Category20[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 OEOE Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "odd_even_list = list(set([x for x in odd_even_dict.values()]))\n",
    "\n",
    "EEEO_patterns = ['EEEO', 'EEOE', 'EOEE', 'OEEE']\n",
    "OOOE_patterns = ['OOOE', 'OOEO', 'OEOO', 'EOOO']\n",
    "EEOO_patterns = ['EEOO', 'EOEO', 'EOOE']\n",
    "OOEE_patterns = ['OOEE', 'OEOE', 'OEEO']\n",
    "OEOE_other_patterns = list(\n",
    "    filter(lambda x: x not in EEEO_patterns + OOOE_patterns + EEOO_patterns + OOEE_patterns, odd_even_list)\n",
    ")\n",
    "\n",
    "splits_list = [EEEO_patterns, OOOE_patterns, EEOO_patterns, OOEE_patterns, OEOE_other_patterns]\n",
    "populateLineChart(data_df, group_by='odd_even', splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 BSBS Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_small_list = list(set([x for x in big_small_dict.values()]))\n",
    "\n",
    "BBBS_patterns = ['BBBS', 'BBSB', 'BSBB', 'SBBB']\n",
    "SSSB_patterns = ['SSSB', 'SSBS', 'SBSS', 'BSSS']\n",
    "BBSS_patterns = ['BBSS', 'BSBS', 'BSSB']\n",
    "SSBB_patterns = ['SSBB', 'SBSB', 'SBBS']\n",
    "BSBS_other_patterns = list(\n",
    "    filter(lambda x: x not in BBBS_patterns + SSSB_patterns + BBSS_patterns + SSBB_patterns, big_small_list)\n",
    ")\n",
    "\n",
    "splits_list = [BBBS_patterns, SSSB_patterns, BBSS_patterns, SSBB_patterns, BSBS_other_patterns]\n",
    "populateLineChart(data_df, group_by='big_small', splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Number Summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in data_df['company_code'].unique():\n",
    "    colors = itertools.cycle(Category20[9])\n",
    "    fig = figure(title=f'{company.title()} - Number Summation',\n",
    "                 x_axis_type='datetime',\n",
    "                 x_axis_label='Dates', y_axis_label='Sum',\n",
    "                 width=950, height=500,\n",
    "                 toolbar_location='above')\n",
    "    \n",
    "    items = []\n",
    "    for category in data_df['category'].unique():\n",
    "        tmp_df = data_df[(data_df['category'] == category) & (data_df['company_code'] == company)]\n",
    "        tmp_dict = tmp_df.groupby(tmp_df.index).agg({'number': ', '.join}).to_dict('index')\n",
    "        \n",
    "        totals = []\n",
    "        dates = tmp_df.index.unique()\n",
    "        for date in dates:\n",
    "            tmp_list = tmp_dict.get(date)['number'].replace(' ', '').split(',')\n",
    "            totals.append(sum([int(x) for x in tmp_list]))\n",
    "            \n",
    "        source = ColumnDataSource(data=dict(\n",
    "            dates=dates,\n",
    "            totals=totals,\n",
    "        ))\n",
    "        glyph1 = fig.circle('dates', 'totals', color=next(colors), alpha=.5, source=source)\n",
    "        glyph2 = fig.line('dates', 'totals', color=next(colors), alpha=.8, source=source)\n",
    "        items.append((category, [glyph1, glyph2]))\n",
    "        \n",
    "    fig.add_layout(Legend(items=items, location='bottom_left', orientation='horizontal', click_policy='hide'), 'below')\n",
    "    fig.add_tools(HoverTool(\n",
    "        tooltips = [\n",
    "            ('Date', '@dates{%F}'),\n",
    "            ('Sum', '@totals'),\n",
    "        ],\n",
    "        formatters={\n",
    "            'dates': 'datetime',\n",
    "        },\n",
    "        mode='vline'\n",
    "    ))\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Candidates\n",
    "### 6.1 Cluster's Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidateCount(category_df, groupby):\n",
    "    delimiter = ''\n",
    "    output_list = []\n",
    "    \n",
    "    if groupby in category_df.columns:\n",
    "        count_dict = category_df.groupby(groupby).size().to_dict()\n",
    "    \n",
    "    if groupby == 'pattern':\n",
    "        title = 'ABCD Pattern'\n",
    "        output_list = [AAAB_patterns, AABB_patterns, AABC_patterns, ABBC_patterns, ABCD_other_patterns]\n",
    "        \n",
    "    elif groupby == 'odd_even':\n",
    "        title = 'OEOE Pattern'\n",
    "        output_list = [EEEO_patterns, OOOE_patterns, EEOO_patterns, OOEE_patterns, OEOE_other_patterns]\n",
    "        \n",
    "    elif groupby == 'big_small':\n",
    "        title = 'BSBS Pattern'\n",
    "        output_list = [BBBS_patterns, SSSB_patterns, BBSS_patterns, SSBB_patterns, BSBS_other_patterns]\n",
    "        \n",
    "    elif groupby == 'digit_groups':\n",
    "        title = 'Digit Groups'\n",
    "        tmp_list = []\n",
    "        for by in ['group_4', 'group_3', 'group_2', 'group_1']:\n",
    "            count_dict = category_df.groupby(by).size().to_dict()\n",
    "            tmp_list.append([f'{x}: {count_dict.get(x) : >5}' for x in count_dict.keys()])\n",
    "\n",
    "        output_list = []\n",
    "        for index, x in enumerate(tmp_list[0]):\n",
    "            output_list.append([y[index] for y in tmp_list])\n",
    "        \n",
    "    \n",
    "    print(f'\\n{title}')\n",
    "    for index, pattern in enumerate(output_list):\n",
    "        if groupby == 'digit_groups':\n",
    "            output = f'{delimiter:>5} '.join([f'{x}' for x in pattern])\n",
    "        else:\n",
    "            output = f'{delimiter:>5} '.join([f'{x}: {count_dict.get(x) : >5}' for x in pattern])\n",
    "        print(f'{index+1:>2}. {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateCount(category_df, 'pattern')\n",
    "candidateCount(category_df, 'odd_even')\n",
    "candidateCount(category_df, 'big_small')\n",
    "candidateCount(category_df, 'digit_groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_cand = [] + AABC_patterns + ABBC_patterns + ['ABBC', 'ABCD']\n",
    "group_4_cand = []\n",
    "group_3_cand = []\n",
    "group_2_cand = []\n",
    "group_1_cand = []\n",
    "odd_even_cand = []\n",
    "big_small_cand = []\n",
    "\n",
    "candidates = category_df[((len(pattern_cand) <= 0) | (category_df['pattern'].isin(pattern_cand))) &\n",
    "                         (((len(group_4_cand) <= 0) | category_df['group_4'].isin(group_4_cand))) &\n",
    "                         (((len(group_3_cand) <= 0) | category_df['group_3'].isin(group_3_cand))) &\n",
    "                         (((len(group_2_cand) <= 0) | category_df['group_2'].isin(group_2_cand))) &\n",
    "                         (((len(group_1_cand) <= 0) | category_df['group_1'].isin(group_1_cand))) &\n",
    "                         (((len(odd_even_cand) <= 0) | category_df['odd_even'].isin(odd_even_cand))) &\n",
    "                         (((len(big_small_cand) <= 0) | category_df['big_small'].isin(big_small_cand)))]\n",
    "\n",
    "# candidates.to_csv(f'candidates.csv', sep=';', index=None, header=True)\n",
    "candidates.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
