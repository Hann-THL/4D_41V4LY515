{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# plot pandas dates\n",
    "from pandas.tseries import converter\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "# interactive graphs on jupyter notebook\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = '../resources/data/4D_result_2018-01-01_2018-12-31.csv'\n",
    "raw_data = pd.read_csv(filename, sep=';', dtype={'number': str})\n",
    "# raw_data.info()\n",
    "# raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform_data = raw_data.copy()\n",
    "transform_data.loc[transform_data['company_code'] == 'DMC', 'company_code'] = 'Da Ma Cai'\n",
    "transform_data.loc[transform_data['company_code'] == 'MAG', 'company_code'] = 'Magnum'\n",
    "transform_data.loc[transform_data['company_code'] == 'ST', 'company_code'] = 'Sports Toto'\n",
    "\n",
    "transform_data.loc[transform_data['category'] == 'FST', 'category'] = '1st'\n",
    "transform_data.loc[transform_data['category'] == 'SCD', 'category'] = '2nd'\n",
    "transform_data.loc[transform_data['category'] == 'TRD', 'category'] = '3rd'\n",
    "transform_data.loc[transform_data['category'] == 'SP', 'category'] = 'Special'\n",
    "transform_data.loc[transform_data['category'] == 'CONS', 'category'] = 'Consolation'\n",
    "# transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_from = transform_data.min()['draw_date']\n",
    "date_to = transform_data.max()['draw_date']\n",
    "\n",
    "# date_from = '2019-07-01'\n",
    "# date_to = '2019-07-30'\n",
    "\n",
    "company_code = 'Magnum'\n",
    "data = transform_data[(transform_data['number'] != '----') &\n",
    "                      (transform_data['company_code'] == company_code) &\n",
    "                      (transform_data['draw_date'] >= date_from) &\n",
    "                      (transform_data['draw_date'] <= date_to)]\n",
    "data = data.sort_values(by=['draw_date', 'company_code', 'position'])\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Manipulation\n",
    "### 4.1 Populate time_position as sorting order to plot on line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_dict = data.groupby(['draw_date', 'company_code']).agg({\n",
    "    'number': ', '.join\n",
    "}).to_dict('index')\n",
    "\n",
    "for key in tmp_dict.keys():\n",
    "    tmp_list = tmp_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    tmp_list.sort()\n",
    "    tmp_dict.get(key)['number'] = ', '.join(tmp_list)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    key = (row['draw_date'], row['company_code'])\n",
    "    tmp_list = tmp_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    data.loc[index, 'time_position'] = str(tmp_list.index(row['number'])).zfill(2) + ':00'\n",
    "\n",
    "data = data.sort_values(by=['draw_date', 'company_code', 'time_position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Populate clustering categories for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/data/number_category.csv'\n",
    "category_data = pd.read_csv(filename, sep=';', dtype={'number': str})\n",
    "# category_data.info()\n",
    "# category_data.describe(include='all')\n",
    "\n",
    "# Build dictionaries\n",
    "pattern_dict = dict(zip(category_data['number'], category_data['pattern']))\n",
    "group_4_dict = dict(zip(category_data['number'], category_data['group_4']))\n",
    "group_3_dict = dict(zip(category_data['number'], category_data['group_3']))\n",
    "group_2_dict = dict(zip(category_data['number'], category_data['group_2']))\n",
    "group_1_dict = dict(zip(category_data['number'], category_data['group_1']))\n",
    "odd_even_dict = dict(zip(category_data['number'], category_data['odd_even']))\n",
    "big_small_dict = dict(zip(category_data['number'], category_data['big_small']))\n",
    "\n",
    "# Dictionaries lookup\n",
    "data['pattern'] = [pattern_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['group_4'] = [group_4_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['group_3'] = [group_3_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['group_2'] = [group_2_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['group_1'] = [group_1_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['odd_even'] = [odd_even_dict[row['number']] for index, row in data.iterrows()]\n",
    "data['big_small'] = [big_small_dict[row['number']] for index, row in data.iterrows()]\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Visualization\n",
    "### 5.1 Number Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_data = data[data['category'] == '1st']\n",
    "second_data = data[data['category'] == '2nd']\n",
    "third_data = data[data['category'] == '3rd']\n",
    "special_data = data[data['category'] == 'Special']\n",
    "consolation_data = data[data['category'] == 'Consolation']\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in first_data.iterrows()]\n",
    "first_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in second_data.iterrows()]\n",
    "second_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in third_data.iterrows()]\n",
    "third_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in special_data.iterrows()]\n",
    "special_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in consolation_data.iterrows()]\n",
    "consolation_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "str_datetimes = [str(row['draw_date']) + ' ' + str(row['time_position']) for index, row in data.iterrows()]\n",
    "data_datetimes = [dt.strptime(str_datetime, '%Y-%m-%d %H:%M') for str_datetime in str_datetimes]\n",
    "\n",
    "first_numbers = [int(row['number']) for index, row in first_data.iterrows()]\n",
    "second_numbers = [int(row['number']) for index, row in second_data.iterrows()]\n",
    "third_numbers = [int(row['number']) for index, row in third_data.iterrows()]\n",
    "special_numbers = [int(row['number']) for index, row in special_data.iterrows()]\n",
    "consolation_numbers = [int(row['number']) for index, row in consolation_data.iterrows()]\n",
    "data_numbers = [int(row['number']) for index, row in data.iterrows()]\n",
    "\n",
    "mpld3.enable_notebook()\n",
    "plt.rcParams['figure.figsize'] = [13, 7]\n",
    "plt.plot(first_datetimes, first_numbers, marker='*', c='r', ls='none', ms='10', label='1st')\n",
    "plt.plot(second_datetimes, second_numbers, marker='*', c='g', ls='none', ms='10', label='2nd')\n",
    "plt.plot(third_datetimes, third_numbers, marker='*', c='b', ls='none', ms='10', label='3rd')\n",
    "plt.plot(special_datetimes, special_numbers, marker='x', c='m', ls='none', ms='8', label='Special')\n",
    "plt.plot(consolation_datetimes, consolation_numbers, marker='x', c='c', ls='none', ms='8', label='Consolation')\n",
    "plt.plot(data_datetimes, data_numbers, marker='', c='k', ls='none')\n",
    "\n",
    "plt.title(f'{company_code} Analysis ({date_from} to {date_to})', fontsize=15)\n",
    "plt.xlabel('Draw Date', fontsize=12)\n",
    "plt.ylabel('4D Number', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ABCD Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populateLineChart(data, group_by, title, date_range, splits_list, split_by='default'):\n",
    "    groups_results = []\n",
    "    tmp_dict = data.groupby([group_by, 'draw_date']).size().to_dict()\n",
    "    tmp_list = [x for x in tmp_dict.items()]\n",
    "    \n",
    "    groups = data[group_by].unique()\n",
    "    for group in groups:\n",
    "        tmp_data = list(filter(lambda x: x[0][0] == group, tmp_list))\n",
    "        groups_results.append((group, [(x[0][1], x[1]) for x in tmp_data]))\n",
    "    \n",
    "    tmp_list = [[y[0] for y in x[1]] for x in groups_results]\n",
    "    str_all_dates = list(set(sum(tmp_list, [])))\n",
    "    str_all_dates.sort()\n",
    "    \n",
    "    splits_results = []\n",
    "    for splits in splits_list:\n",
    "        if split_by == 'index':\n",
    "            splits_results.append(list(filter(lambda x: groups_results.index(x) in splits, groups_results)))\n",
    "        else:\n",
    "            splits_results.append(list(filter(lambda x: x[0] in splits, groups_results)))\n",
    "    \n",
    "    for results in splits_results:\n",
    "        for index, x in enumerate(results):\n",
    "            dates = [dt.strptime(str_date, '%Y-%m-%d') for str_date in str_all_dates]\n",
    "            occurrences = [0 for date in dates]\n",
    "\n",
    "            str_dates = [y[0] for y in x[1]]\n",
    "            for y in x[1]:\n",
    "                if y[1] == 0:\n",
    "                    continue\n",
    "                str_date = y[0]\n",
    "                occurrences[str_all_dates.index(str_date)] = y[1]\n",
    "                \n",
    "            plt.plot(dates, occurrences, marker='o', ls='--', label=x[0])\n",
    "            \n",
    "        tmp_list = sorted([x[0] for x in results])\n",
    "        subtitle = ''\n",
    "        for index, splits in enumerate(splits_list):\n",
    "            if ((tmp_list == sorted(splits)) | (all(x in splits for x in tmp_list))) :\n",
    "                subtitle = index < len(splits_list) -1 and f'{splits[0]} Pattern' or 'Other Pattern'\n",
    "                break\n",
    "        \n",
    "        plt.title(title + subtitle, fontsize=15)\n",
    "        plt.xlabel(f'Draw Date ({date_range})', fontsize=12)\n",
    "        plt.ylabel('Occurrence', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populatePieChart(pie_data, group_by, title):\n",
    "    pie_dict = pie_data.groupby(group_by).size().to_dict()\n",
    "    pie_dict = dict(sorted(pie_dict.items(), key=lambda x: x[1]))\n",
    "    pie_sizes = [x for x in pie_dict.values()]\n",
    "    pie_labels = [x for x in pie_dict]\n",
    "    pie_explode = [.0175 for element in pie_labels]\n",
    "\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.axis('equal')\n",
    "    plt.pie(pie_sizes, labels=pie_labels, autopct='%0.2f%%', startangle=90, explode=pie_explode)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_list = list(set([x for x in pattern_dict.values()]))\n",
    "\n",
    "AAAB_patterns = ['AAAB', 'AABA', 'ABAA']\n",
    "AABB_patterns = ['AABB', 'ABAB', 'ABBA']\n",
    "AABC_patterns = ['AABC', 'ABAC', 'ABCA']\n",
    "ABBC_patterns = ['ABBC', 'ABCB']\n",
    "ABCD_other_patterns = list(\n",
    "    filter(lambda x: x not in AAAB_patterns + AABB_patterns + AABC_patterns + ABBC_patterns, pattern_list)\n",
    ")\n",
    "\n",
    "title = f'{company_code} - '\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [AAAB_patterns, AABB_patterns, AABC_patterns, ABBC_patterns, ABCD_other_patterns]\n",
    "populateLineChart(data, group_by='pattern', title=title, date_range=date_range, splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - ABCD Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='pattern', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 N*** Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = f'{company_code} - N*** Pattern'\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "populateLineChart(data, group_by='group_4', title=title, date_range=date_range, splits_list=splits_list, split_by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - N*** Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='group_4', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 \\*N** Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = f'{company_code} - *N** Pattern'\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "populateLineChart(data, group_by='group_3', title=title, date_range=date_range, splits_list=splits_list, split_by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - *N** Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='group_3', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 \\*\\*N* Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = f'{company_code} - **N* Pattern'\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "populateLineChart(data, group_by='group_2', title=title, date_range=date_range, splits_list=splits_list, split_by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - **N* Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='group_2', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 \\*\\*\\*N Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = f'{company_code} - ***N Pattern'\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "populateLineChart(data, group_by='group_1', title=title, date_range=date_range, splits_list=splits_list, split_by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - ***N Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='group_1', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 OEOE Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_even_list = list(set([x for x in odd_even_dict.values()]))\n",
    "\n",
    "EEEO_patterns = ['EEEO', 'EEOE', 'EOEE', 'OEEE']\n",
    "OOOE_patterns = ['OOOE', 'OOEO', 'OEOO', 'EOOO']\n",
    "EEOO_patterns = ['EEOO', 'EOEO', 'EOOE']\n",
    "OOEE_patterns = ['OOEE', 'OEOE', 'OEEO']\n",
    "OEOE_other_patterns = list(\n",
    "    filter(lambda x: x not in EEEO_patterns + OOOE_patterns + EEOO_patterns + OOEE_patterns, odd_even_list)\n",
    ")\n",
    "\n",
    "title = f'{company_code} - '\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [EEEO_patterns, OOOE_patterns, EEOO_patterns, OOEE_patterns, OEOE_other_patterns]\n",
    "populateLineChart(data, group_by='odd_even', title=title, date_range=date_range, splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - OEOE Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='odd_even', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 BSBS Pattern Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_small_list = list(set([x for x in big_small_dict.values()]))\n",
    "\n",
    "BBBS_patterns = ['BBBS', 'BBSB', 'BSBB', 'SBBB']\n",
    "SSSB_patterns = ['SSSB', 'SSBS', 'SBSS', 'BSSS']\n",
    "BBSS_patterns = ['BBSS', 'BSBS', 'BSSB']\n",
    "SSBB_patterns = ['SSBB', 'SBSB', 'SBBS']\n",
    "BSBS_other_patterns = list(\n",
    "    filter(lambda x: x not in BBBS_patterns + SSSB_patterns + BBSS_patterns + SSBB_patterns, big_small_list)\n",
    ")\n",
    "\n",
    "title = f'{company_code} - '\n",
    "date_range = f'{date_from} to {date_to}'\n",
    "splits_list = [BBBS_patterns, SSSB_patterns, BBSS_patterns, SSBB_patterns, BSBS_other_patterns]\n",
    "populateLineChart(data, group_by='big_small', title=title, date_range=date_range, splits_list=splits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pie_data in [first_data, second_data, third_data, special_data, consolation_data]:\n",
    "    str_categories = ', '.join(pie_data['category'].unique())\n",
    "    title = f'{company_code} {str_categories} Price - BSBS Pattern ({date_from} to {date_to})'\n",
    "    populatePieChart(pie_data, group_by='big_small', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Number Summation Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dict = first_data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "second_dict = second_data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "third_dict = third_data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "special_dict = special_data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "consolation_dict = consolation_data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "data_dict = data.groupby('draw_date').agg({'number': ', '.join}).to_dict('index')\n",
    "\n",
    "dates = []\n",
    "first_totals = []\n",
    "second_totals = []\n",
    "third_totals = []\n",
    "special_totals = []\n",
    "consolation_totals = []\n",
    "data_totals = []\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    dates.append(dt.strptime(key, '%Y-%m-%d'))\n",
    "    \n",
    "    tmp_list = first_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    first_totals.append(sum([int(x) for x in tmp_list]))\n",
    "    \n",
    "    tmp_list = second_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    second_totals.append(sum([int(x) for x in tmp_list]))\n",
    "    \n",
    "    tmp_list = third_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    third_totals.append(sum([int(x) for x in tmp_list]))\n",
    "    \n",
    "    tmp_list = special_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    special_totals.append(sum([int(x) for x in tmp_list]))\n",
    "    \n",
    "    tmp_list = consolation_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    consolation_totals.append(sum([int(x) for x in tmp_list]))\n",
    "    \n",
    "    tmp_list = data_dict.get(key)['number'].replace(' ', '').split(',')\n",
    "    data_totals.append(sum([int(x) for x in tmp_list]))\n",
    "\n",
    "plt.plot(dates, first_totals, marker='None', c='r', ls='-', label='1st')\n",
    "plt.plot(dates, second_totals, marker='None', c='g', ls='-', label='2nd')\n",
    "plt.plot(dates, third_totals, marker='None', c='b', ls='-', label='3rd')\n",
    "plt.plot(dates, special_totals, marker='None', c='m', ls='-', label='Special')\n",
    "plt.plot(dates, consolation_totals, marker='None', c='c', ls='-', label='Consolation')\n",
    "plt.plot(dates, data_totals, marker='None', c='k', ls='-', label='Total')\n",
    "\n",
    "plt.title(f'{company_code} - Number Summation Analysis ({date_from} to {date_to})', fontsize=15)\n",
    "plt.xlabel('Draw Date', fontsize=12)\n",
    "plt.ylabel('Sum', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cluster's Candidates Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberCount(category_data, groupby):\n",
    "    delimiter = ''\n",
    "    output_list = []\n",
    "    \n",
    "    if groupby in category_data.columns:\n",
    "        count_dict = category_data.groupby(groupby).size().to_dict()\n",
    "    \n",
    "    if groupby == 'pattern':\n",
    "        title = 'ABCD Pattern'\n",
    "        output_list = [AAAB_patterns, AABB_patterns, AABC_patterns, ABBC_patterns, ABCD_other_patterns]\n",
    "        \n",
    "    elif groupby == 'odd_even':\n",
    "        title = 'OEOE Pattern'\n",
    "        output_list = [EEEO_patterns, OOOE_patterns, EEOO_patterns, OOEE_patterns, OEOE_other_patterns]\n",
    "        \n",
    "    elif groupby == 'big_small':\n",
    "        title = 'BSBS Pattern'\n",
    "        output_list = [BBBS_patterns, SSSB_patterns, BBSS_patterns, SSBB_patterns, BSBS_other_patterns]\n",
    "        \n",
    "    elif groupby == 'digit_groups':\n",
    "        title = 'Digit Groups'\n",
    "        tmp_list = []\n",
    "        for by in ['group_4', 'group_3', 'group_2', 'group_1']:\n",
    "            count_dict = category_data.groupby(by).size().to_dict()\n",
    "            tmp_list.append([f'{x}: {count_dict.get(x) : >5}' for x in count_dict.keys()])\n",
    "\n",
    "        output_list = []\n",
    "        for index, x in enumerate(tmp_list[0]):\n",
    "            output_list.append([y[index] for y in tmp_list])\n",
    "        \n",
    "    \n",
    "    print(f'\\n{title}')\n",
    "    for index, pattern in enumerate(output_list):\n",
    "        if groupby == 'digit_groups':\n",
    "            output = f'{delimiter:>5} '.join([f'{x}' for x in pattern])\n",
    "        else:\n",
    "            output = f'{delimiter:>5} '.join([f'{x}: {count_dict.get(x) : >5}' for x in pattern])\n",
    "        print(f'{index+1:>2}. {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberCount(category_data, 'pattern')\n",
    "numberCount(category_data, 'odd_even')\n",
    "numberCount(category_data, 'big_small')\n",
    "numberCount(category_data, 'digit_groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Candidates Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_cand = [] + AABC_patterns + ABBC_patterns + ['ABBC', 'ABCD']\n",
    "group_4_cand = []\n",
    "group_3_cand = []\n",
    "group_2_cand = []\n",
    "group_1_cand = []\n",
    "odd_even_cand = []\n",
    "big_small_cand = []\n",
    "\n",
    "candidates = category_data[((len(pattern_cand) <= 0) | (category_data['pattern'].isin(pattern_cand))) &\n",
    "                           (((len(group_4_cand) <= 0) | category_data['group_4'].isin(group_4_cand))) &\n",
    "                           (((len(group_3_cand) <= 0) | category_data['group_3'].isin(group_3_cand))) &\n",
    "                           (((len(group_2_cand) <= 0) | category_data['group_2'].isin(group_2_cand))) &\n",
    "                           (((len(group_1_cand) <= 0) | category_data['group_1'].isin(group_1_cand))) &\n",
    "                           (((len(odd_even_cand) <= 0) | category_data['odd_even'].isin(odd_even_cand))) &\n",
    "                           (((len(big_small_cand) <= 0) | category_data['big_small'].isin(big_small_cand)))]\n",
    "\n",
    "# candidates.to_csv(f'{company_code}_candidates_based_on_data_{date_from}_{date_to}.csv', sep=';', index=None, header=True)\n",
    "candidates.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
