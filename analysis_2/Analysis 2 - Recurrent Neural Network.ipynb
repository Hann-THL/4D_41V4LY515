{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, CuDNNLSTM, Dropout\n",
    "\n",
    "# change tensorflow default behavior (where it uses all of the memory at the outset)\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "# plot pandas dates\n",
    "from pandas.tseries import converter\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "# interactive graphs on jupyter notebook\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../resources/data/4D_result_2018-01-01_2018-12-31.csv'\n",
    "raw_data = pd.read_csv(filename, sep=';', dtype={'number': str})\n",
    "# raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform_data = raw_data.copy()\n",
    "transform_data.loc[transform_data['company_code'] == 'DMC', 'company_code'] = 'Da Ma Cai'\n",
    "transform_data.loc[transform_data['company_code'] == 'MAG', 'company_code'] = 'Magnum'\n",
    "transform_data.loc[transform_data['company_code'] == 'ST', 'company_code'] = 'Sports Toto'\n",
    "\n",
    "transform_data.loc[transform_data['category'] == 'FST', 'category'] = '1st'\n",
    "transform_data.loc[transform_data['category'] == 'SCD', 'category'] = '2nd'\n",
    "transform_data.loc[transform_data['category'] == 'TRD', 'category'] = '3rd'\n",
    "transform_data.loc[transform_data['category'] == 'SP', 'category'] = 'Special'\n",
    "transform_data.loc[transform_data['category'] == 'CONS', 'category'] = 'Consolation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_from = transform_data.min()['draw_date']\n",
    "date_to = transform_data.max()['draw_date']\n",
    "\n",
    "# date_from = '2019-01-01'\n",
    "# date_to = '2019-07-31'\n",
    "\n",
    "categories = ['1st', '2nd', '3rd', 'Special', 'Consolation']\n",
    "price_count = sum(list(map(lambda x:\n",
    "                           (x == '1st' or x == '2nd' or x == '3rd') and 1 or\n",
    "                           (x == 'Special' or x == 'Consolation') and 10 or 0, categories\n",
    "                          )))\n",
    "\n",
    "company_code = 'Magnum'\n",
    "data = transform_data[(transform_data['number'] != '----') &\n",
    "                      (transform_data['company_code'] == company_code) &\n",
    "                      (transform_data['draw_date'] >= date_from) &\n",
    "                      (transform_data['draw_date'] <= date_to) &\n",
    "                      (transform_data['category'].isin(categories))]\n",
    "data = data.sort_values(by=['draw_date', 'company_code', 'category', 'position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pre-Processing\n",
    "### 4.1 Input & Target Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "period_arr = []\n",
    "period_dict = data.groupby('draw_date').groups\n",
    "for k in period_dict.keys():\n",
    "    period_arr.append([data.loc[i]['number'] for i in period_dict.get(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_value = 9999\n",
    "input_data = []\n",
    "target_data = []\n",
    "\n",
    "period_count = 1\n",
    "for i, arr in enumerate(period_arr): \n",
    "    if i == len(period_arr) - period_count:\n",
    "        break\n",
    "    \n",
    "    tmp_arr = []\n",
    "    for n in range(period_count):\n",
    "        tmp_arr.append(\n",
    "            list(filter(lambda x: x[0] == i+n, enumerate(period_arr)))[0][1]\n",
    "        )\n",
    "    \n",
    "    # Data Normalization\n",
    "    input_data.append(\n",
    "        [[float(n) / max_value for n in tmp_arr2] for tmp_arr2 in tmp_arr]\n",
    "    )\n",
    "    target_data.append(\n",
    "        [float(n) / max_value for n in period_arr[i + period_count]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(input_data, dtype=float)\n",
    "target_data = np.array(target_data, dtype=float)\n",
    "\n",
    "print('input_data.shape\\t', input_data.shape)\n",
    "print('target_data.shape\\t', target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train & Test Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.2, random_state=4)\n",
    "\n",
    "print('x_train.shape', x_train.shape)\n",
    "print('x_test.shape', x_test.shape)\n",
    "\n",
    "# print('x_train:')\n",
    "# print(x_train[:3])\n",
    "# print('y_train:')\n",
    "# print(y_train[:3])\n",
    "# print()\n",
    "\n",
    "# start_index = list(filter(lambda x: x[1][0] == '2644', enumerate(period_arr)))[0][0]\n",
    "# print('input:')\n",
    "# for n in range(period_count):\n",
    "#     print(period_arr[start_index + n])\n",
    "    \n",
    "# print('target:')\n",
    "# print(period_arr[start_index + period_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural Network\n",
    "### 5.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(CuDNNLSTM(units=128, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(units=128, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(CuDNNLSTM(units=128, return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(CuDNNLSTM(units=128))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=price_count))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = dt.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "history = model.fit(x_train, y_train, epochs=200, validation_data=(x_test, y_test))\n",
    "end_time = dt.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Result Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Start:\\t{start_time}')\n",
    "print(f'Train End:\\t{end_time}')\n",
    "\n",
    "results = model.predict(x_test)\n",
    "\n",
    "print('results.shape', results.shape)\n",
    "print('y_test.shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpld3.enable_notebook()\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "for i, arr in enumerate(y_test[:10]):\n",
    "    plt.title(f'Test Data: {i+1}')\n",
    "    plt.plot(range(results.shape[1]), results[i], c='r', marker='*', ls='none')\n",
    "    plt.plot(range(results.shape[1]), arr, c='g', marker='x', ls='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], c='g', label='loss')\n",
    "plt.plot(history.history['val_loss'], c='b', label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
